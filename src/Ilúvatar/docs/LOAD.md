# Running Experiments

## Python abstraction

A Python 'library' sits alongside the Rust library to abstract away many details and boilerplate we have come across when running large-scale experiments.
These including running dozens of simulations in parallel, configuring clusters, and hosts for live experimental runs.

The Python module for running these experiments is [here](../../load/run/) and for analyzing results in a [co-located folder](../../load/analysis/).
These make orchstrating running and post-processing only take a handful of lines of code.
The code contains some documentation, but comparing against [our working examples](./examples/README.md) is the easiest way to get started.

## Load Generation

The load generation tool can be used directly, and some features aren't used in the abstraction Python scripts described above.

### Shared Params

All commands share some common paramaters.
These must be passed *before* the command value.

1. `--port`, or `-p` is the port the target is listening on.
1. `--host`, or `-h` is the host name or IP address the target is listening on.
1. `--out`, or `-o` specifies the output folder to store results in.
1. `--help` prints help information of shared information.

```sh
iluvatar_load_gen -p 8079 -h localhost trace 
iluvatar_load_gen --help
```

`--help` can also be specified for each command, with detailed help for it.

```bash
iluvatar_load_gen trace --help
```

### Trace load

This allows a series of predetermined function invocations to be run on either a worker or controller.
Two csv files control what functions are run at what time, to the millisecond.

```sh
iluvatar_load_gen -p 100 -h localhost trace 
```

1. `--target`, `-t`: What is the experiment targeting?
Specifying `worker` and it will use RPCs to communicate with a single worker directly.
This will also generate transaction IDs internally as well.
Or `controller` will then use HTTP requests to communcate with a controller.
The target will affect the results file, i.e. we can't have controller latency information if we are targeting a worker.

1. `--setup`: Is the experiment is a simulation of Ilúvatar or a live system?
Passing `simulation` has the load generator create a simulated version of the target and running load on that system.
The simulation *does not* run real function code, and invocations *do not* take up CPU or memory resources.
Passing `live` means the system has been set up elsewhere and the load tool will communicate with it remotely.

1. `--input`, `-i`: A csv input file with individual invocation details for functions. This function **must** be in sorted order on invocatin time
   1. `func_name`: A unique string that maps to the `func_name` in the `metadata` file
   1. `invoke_time_ms`: The time in milliseconds that the function should be invoked at. This is a 0-based time, so if no function is invoked until some time `X`, it will wait.

1. `--metadata`, `-m`: A csv file with function metadata that is associated with the trace file passed in.
It expects the file to have the following columns: `func_name,cold_dur_ms,warm_dur_ms,mem_mb` .
   1. `func_name`: A string function name, must be unique
   1. `cold_dur_ms`: The cold execution duration in milliseconds
   1. `warm_dur_ms`: The warm execution duration in milliseconds
   1. `mem_mb`: The memory usage in megabytes

1. `--load-type`, `-l`: This load generator can support two different types of functions to run.
This parameter is only relevant when running against a `live` system.
   1. Synthetic load inside each container started by workers can be achieved via [Lookbusy](http://www.devin.com/lookbusy/).
   The function's runtime characteristics (cold/warm execution time and memory usage) are controlled by lookbusy.
   The values fed to it are taken from the trace metadata to simulate variable functions running inside the system.
   This load method can be specified by passing `lookbusy`, and is the default.

   1. Real code can be run on the functions using modified [FunctionBench](https://github.com/ddps-lab/serverless-faas-workbench) applications.
   The modified programs can be found [nearby](src/load/functions/python3/functions).
   If using real functions, you **must** pass `--function-data` in order for the load tool to find the function with the closest runtime characteristics to each function in the trace.
   It will then run that code when the function is invoked.
   This load method can be specified by passing `functions`.

1. `--function-data`: If using the `functions` option for `--load-type`, a valid json file must be passed here.
This must have runtime data for a list of functions that will be run as placeholders for the functions in the actual trace.
This file can be generated by another command of this tool, the[benchmark](#benchmark-load).
This parameter is only relevant when running against a `live` system.

1. `--worker-config`: A worker config json file, more details on its composition can be found [here](./WORKER.md#configuration).
Each worker will have an identical configuration.
This value is only relevant, but required, if running a simulated controller or worker.

1. `--controller-config`: A controller config json file, more details on its composition can be found [here](./CONTROLLER.md#configuration).
This value is only relevant, but required, if running a simulated controller

1. `--workers`, `-w`: The number of simulated workers to create.
This value is only relevant if running a simulated controller

1. `--prewarm`, `-p`: The number of containers to pre-warm for each function.
Defaults to 0.

#### Generating Traces

The two CSV files for metadata and invocations must match the various fields detailed by their Rust struct equivalents, [Function](../iluvatar_load_gen/src/trace/trace.rs) and [CsvInvocation](../iluvatar_load_gen/src/trace/trace.rs) respectively.

Generating traces is currently done externally using Python scripts.
This is done as preparing and parsing the Azure workload data is resource intensive.

An example of creating a pre-planned invocation shape is in [this script](../../load/generation/four_funcs.py).
A complex scenario of preparing the Azure data and using it to generate a trace can be found in [the examples](../Ilúvatar/docs/examples/azure-trace/generate-trace.sh).

#### Trace examples

An example load call to a live system:

```bash
iluvatar_load_gen -p 100 -h localhost trace --target "worker" --setup "live" --input "/my/trace/input.csv" --metadata "/my/trace/metadata-input.csv" --load-type "functions" --function-data "/my/function/data.json
```

An example load call for a simulation:

```bash
iluvatar_load_gen -p 100 -h localhost trace --target "controller" --setup "simulation" --input "/my/trace/input.csv" --metadata "/my/trace/metadata-input.csv" --worker-config "/my/worker/config.json" --controller-config "/my/controller/config.json" --workers 3
```

### Benchmark load

The `benchmark` command repeatedly runs functions on a system to determine the runtime characteristics of each.
Results of the benchmark will be stored as json, in the format specified by the `BenchmarkStore` struct [here](../iluvatar_load_gen/src/benchmark.rs)

1. `--functions-dir`: A directory holding the functions that are to be benchmarked.
It is assumed that images for each already exist and are available, they are not prepared by this.
It iterates over the sub-directories and uses their names to specify images to run.
The easiest way is to use the `python3` functions in [this folder](../../load/functions/python3/functions) of the repository.

1. `--target`, `-t`: What is the experiment targeting?
Specifying `worker` and it will use RPCs to communicate with a single worker directly.
This will also generate transaction IDs internally as well.
Or `controller` will then use HTTP requests to communcate with a controller.

1. `--cold-iters`: The number of times each function will be created new on the target. These will be cold starts of the function.

1. `--warm-iters`: The number of times each function will be run after a cold iteration is started. These will be warm start of the function.

1. `--run-time`: An alternative to the `*-iter` params.
Functions will be invoked in a closed loop for the specified number of seconds.
Upon finishing, a new invocation will be sent.
The final invocation will complete after the time expires.

1. `--threads`: Run a set number of clients, all invoking the same function.
Clients will synchronize before starting the next function.
Results will be combined into one file.

An example load call for a worker:

```bash
iluvatar_load_gen -p 100 -h localhost benchmark --target "worker" --functions-dir "src/load/functions/python3/functions" --cold-iters 5 --warm-iters 5
```


### Scaling load

This command runs an increasing number of client threads against a worker to test it's ability to scale as the number of requests come in.
It runs a [this](../../load/functions/python3/functions/hello/main.py) simple Python function that does some simple string formatting.
This way invocations aren't primarily limited by the CPU usage and delay of invocations running for a significant time, only by contention and time spent in the worker.

1. `--start`, `-s`: The number of threads to start at
1. `--end`, `-e`: The number of threads to end at
1. `--duration`, `-d`: How long to run before increasing the number of threads

After the duration is done for each number of threads, the throughput results will be stored in a json folder in the `--out` directory.
They will be formatted as a list of the `ThreadResult` struct described [here](../iluvatar_load_gen/src/utils.rs).
