#+TITLE: Iluvatar: Fast and Extensible Local Serverless Computing

#+OPTIONS: toc:nil 

# ** What is Iluvatar?

# Iluvatar provides a platform for Functions as a Service. It is a control-plane which orchestrates the execution of serverless functions.

# Understanding and optimizing the various facets of FaaS deployments, such as scheduling, load-balancing, containerization.

# Iluvatar is a platform for the performance engineering and analysis of FaaS workloads. Among its unique features, it supports a simulation container backend with discrete-event simulator. 

# It is implemented in Rust, and designed with e

# Iluvatar is a state-of-art 

# *** What's with the name?


# ** Why are FaaS platforms interesting? 


Serverless platforms like AWS Lambda provide a convenient and powerful way to deploy and scale cloud-native applications.
With a few lines of code (often an HTTP-triggered function), users can write services for machine learning, IoT, web services, etc.

Iluvatar provides performance-optimized /local/ serverless computing---functions run on your computing baremetal or virtualized hardware. It is the software "control plane" for handling function invocations, and it orchestrates their containerization, scheduling, etc. Iluvatar is the culmination and testing-ground of bleeding-edge FaaS research, and incorporates performance optimizations for function scheduling and reducing cold-starts. Compared to other FaaS platforms like OpenWhisk, it provides more than 100x reduction in function latency. 

Iluvatar was designed with two main intentions:
1. Provide performance and energy optimized local serverless computing on heterogeneous hardware (GPUs).
2. Provide a research platform for developing and evaluating serverless resource-management techniques such as container keep-alive, scheduling, load-balancing, GPU multiplexing, etc. 

* Highlights

** Low overhead and function latency
With careful design and its Rust implementation, we can reduce the function latencies by more than 100x compared to OpenWhisk and other FaaS platforms.
   
** Containerd and Docker isolation
Iluvatar provides an isolated FaaS abstraction: each function runs in its containerized sandbox. Warm containers are reused across non-overlapping invocations to reduce the container and function initialization time. 

** Simple worker-centric design
Distributed container orchestration platforms like Kubernetes require 100s of milliseconds to run functions inside containers. 

** GPU functions 
With the scheduling and MPS and MIG based multiplexing, we are able to run dozens of functions concurrently on NVIDIA GPUs. 


** In-situ simulation
Many scenarios require discrete-event simulation: testing and validating scheduling policies, training reinforcement learning agents, etc. We have created an in-situ simulation architecture, where "real" function containers are replaced by timed-noops. The simulation and real workload has the same code-path and dependencies, which makes transferring policies very easy. 

** Performance engineering and analysis
Load generation and testing, fine-grained analysis of per-function latency. Liberal trace-points for tracing the various operations. 



* Tutorials

** Invoke a registered function

In this exercise, you will invoke a pre-registered function on an already running Iluvatar cluster. You can invoke a function through a regular HTTP request (from your browser or any other HTTP client), or through an RPC interface.

For the HTTP invocation:

=http:// =

** Create and deploy your function

** Set-up Iluvatar

** Lithops Demo 

** Implementing and Evaluating a resource management algorithm using the simulator

In this exercise, you will learn how to implement a simple function queueing policy in Iluvatar, and examine its 

*** Pre-built VM environment

To expedite the process of setting up Iluvatar, we have a pre-built VM image which you can get here [LINK]. Alternatively, you can also log in here:

*** Implementing a 'Random' queueing policy

Create a file rand.rs in src/Ilúvatar/iluvatar_worker_library/src/services/invocation/queueing/. 



* Architecture and key components

*Worker*: Each physical or virtual server runs the [[file:src/Ilúvatar/iluvatar_worker/src/main.rs][worker-daemon]], which manages the containerization, invocation queueing, keep-alive, logging, etc. The [[file:src/Ilúvatar/iluvatar_worker/src/worker.json][worker.json]] configuration file has the key knobs for controlling container properties, scheduling, worker IP address and port, logging, etc.

For interacting with the worker, you can use the [[file:src/Ilúvatar/iluvatar_worker_cli/src/commands.rs][CLI]], which has a one-to-one mapping with the worker API, with functions like ping, invoke, invoke_async, prewarm, register, etc. 

The [[file:src/Ilúvatar/iluvatar_controller/src/main.rs][controller]] acts as the front-end, and performs load-balancing. Iluvatar is a worker-centric architecture, and you can run a worker without the controller. The worker's external API is identical to the controller. 

The worker library has all the interesting implementation for the containerization and scheduling optimizations.


*** Pure FaaS: Strict Isolation

*** Worker-centric architecture

*** Key Components
1. Container Creation
2. Container Pool for Keep-alive
3. Invocation queue for CPU
4. Characteristics Map
5. GPU queueuing
6. Polymorphic Dispatch

*** Other Plumbing
1. RPC interface
2. Ansible [Parameters to select policies, etc] 
3. 

* Performance engineering and analysis

- load testing
- log parsing
- tracing
- running multiple experiments
- Simulation-mode
- 


* Contribute
- List of some open implementation issues: TODO
- List of github issues


